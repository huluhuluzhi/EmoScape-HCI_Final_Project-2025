'''
ç‰ˆæœ¬ V5.0
æœ€ååŠ å…¥äº†èƒŒæ™¯å˜è‰²å’Œæƒ…ç»ªåˆ‡æ¢ç‰¹æ•ˆ
build by ArthurLiu
'''


import streamlit as st
import time
from streamlit_mic_recorder import mic_recorder
from transformers import pipeline

from huggingface_hub import InferenceClient

st.set_page_config(page_title="EmoScape AI", page_icon="ğŸ¨", layout="wide")

HF_API_TOKEN = "hf_xxxxxxxxx" # è‹¥æƒ³ä½¿ç”¨ï¼Œè¯·æ›¿æ¢æˆè‡ªå·±HuggingFaceçš„çœŸå® Token


client = InferenceClient(token=HF_API_TOKEN)

@st.cache_resource
def load_emotion_model():
    return pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")

def load_local_audio(file_path):
    """å®‰å…¨åŠ è½½æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼Œæ‰¾ä¸åˆ°æ–‡ä»¶æ—¶è¿”å› None"""
    try:
        with open(file_path, "rb") as f:
            audio_bytes = f.read()
        return audio_bytes
    except FileNotFoundError:
        st.error(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸¢å¤±: {file_path}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return None

def apply_visual_theme(emotion):
    """
    æ ¹æ®æƒ…ç»ªæ ‡ç­¾ï¼Œæ³¨å…¥å¯¹åº”çš„ CSS èƒŒæ™¯ç‰¹æ•ˆå’Œ Streamlit åŠ¨æ•ˆ
    """

    keyframes = """
    <style>
    @keyframes breathe {
        0% { opacity: 0.8; }
        50% { opacity: 1.0; }
        100% { opacity: 0.8; }
    }
    @keyframes shake {
        0% { transform: translate(1px, 1px) rotate(0deg); }
        10% { transform: translate(-1px, -2px) rotate(-1deg); }
        20% { transform: translate(-3px, 0px) rotate(1deg); }
        30% { transform: translate(3px, 2px) rotate(0deg); }
        40% { transform: translate(1px, -1px) rotate(1deg); }
        50% { transform: translate(-1px, 2px) rotate(-1deg); }
        60% { transform: translate(-3px, 1px) rotate(0deg); }
        70% { transform: translate(3px, 1px) rotate(-1deg); }
        80% { transform: translate(-1px, -1px) rotate(1deg); }
        90% { transform: translate(1px, 2px) rotate(0deg); }
        100% { transform: translate(1px, -2px) rotate(-1deg); }
    }
    @keyframes drift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    </style>
    """
    st.markdown(keyframes, unsafe_allow_html=True)

 
    themes = {
        "ç„¦è™‘": """
            <style>
            .stApp {
                background: linear-gradient(180deg, #636fa4 0%, #e8e8e8 100%);
                background-size: 400% 400%;
                animation: drift 15s ease infinite; /* ç¼“æ…¢æµåŠ¨çš„é›¾æ°”æ„Ÿ */
            }
            </style>
            """,
        "æ‚²ä¼¤": """
            <style>
            .stApp {
                background: linear-gradient(to bottom, #203a43, #2c5364); /* æ·±è“é›¨å¤œ */
                color: #e0e0e0;
            }
            </style>
            """,
        "æ„¤æ€’": """
            <style>
            .stApp {
                background: linear-gradient(to bottom, #4a0000, #1a0505); /* æ·±çº¢å²©æµ† */
                color: #ffcccc;
                animation: breathe 5s infinite; /* æ€¥ä¿ƒçš„å‘¼å¸/è„‰åŠ¨æ„Ÿ */
            }
            </style>
            """,
        "æ²»æ„ˆ": """
            <style>
            .stApp {
                background: linear-gradient(120deg, #a18cd1 0%, #fbc2eb 100%); /* æ¢¦å¹»ç³–æœè‰² */
                background-size: 200% 200%;
                animation: drift 10s ease infinite; /* æŸ”å’ŒæµåŠ¨ */
                color: #333333;
            }
            </style>
            """,
        "ç–²æƒ«": """
            <style>
            .stApp {
                background: linear-gradient(to top, #0f2027, #203a43, #2c5364); /* é™è°§æ˜Ÿç©º */
                color: #d7d7d7;
            }
            </style>
            """
    }

    css = themes.get(emotion, themes["æ²»æ„ˆ"])
    st.markdown(css, unsafe_allow_html=True)

    # 4. è§¦å‘ Streamlit åŸç”Ÿç‰¹æ•ˆ 
    if emotion == "æ²»æ„ˆ":
        st.balloons()  # æ’’æ°”çƒ
    elif emotion == "æ‚²ä¼¤":
        st.snow()      # ä¸‹é›ª (éšå–»ä¸‹é›¨/å¯’å†·)
    elif emotion == "æ„¤æ€’":
        st.toast("ğŸ”¥ æ£€æµ‹åˆ°å¼ºçƒˆæƒ…ç»ªæ³¢åŠ¨ï¼Œæ­£åœ¨å¯åŠ¨é™æ¸©ç¨‹åº...", icon="ğŸ§Š")

def generate_image(prompt):
    
    full_prompt = f"masterpiece, best quality, cinematic lighting, 4k wallpaper, {prompt}, emotional atmosphere, digital art"
    
    try:
        image = client.text_to_image(
            full_prompt,
            model="stabilityai/stable-diffusion-xl-base-1.0"
        )
        return image
    except Exception as e:
        print(f"Error generating image: {e}")
        st.error(f"ç”Ÿæˆå›¾ç‰‡æ—¶é‡åˆ°é—®é¢˜: {e}")
        return None


classifier = load_emotion_model()
candidate_labels = ["ç„¦è™‘", "æ²»æ„ˆ", "æ„¤æ€’", "æ‚²ä¼¤", "ç–²æƒ«"]

# ================= 1. ä¾§è¾¹æ ï¼šå¤šæ¨¡æ€è®¾ç½® =================
with st.sidebar:
    st.header("ğŸ›ï¸ å¤šæ¨¡æ€æ§åˆ¶å°")
    st.success("âœ… æƒ…æ„Ÿè®¡ç®—å¼•æ“ (mDeBERTa) å·²å°±ç»ª")
    st.success("âœ… AIGC ç»˜å›¾å¼•æ“ (SDXL) å·²å°±ç»ª")
    
    st.markdown("---")
    st.markdown("**é—®å·æ•°æ®åº”ç”¨ (Survey Source)**")
    st.caption("åŸºäºã€Šå¤§å­¦ç”Ÿæƒ…ç»ªè¡¨è¾¾ç°çŠ¶è°ƒç ”ã€‹é…ç½®ï¼š")
    enable_audio = st.checkbox("å¯ç”¨ç™½å™ªéŸ³ç–—æ„ˆ (86%ç”¨æˆ·åå¥½)", value=True)
    enable_voice = st.checkbox("å¯ç”¨è¯­éŸ³è¾“å…¥æ¨¡å¼ (60%ç”¨æˆ·åå¥½)", value=True)
    auto_play_audio = st.toggle("ç”Ÿæˆåè‡ªåŠ¨æ’­æ”¾ç™½å™ªéŸ³", value=False)

# ================= 2. ä¸»ç•Œé¢é€»è¾‘ =================
st.title("ğŸ¨ EmoScape: ä½ çš„å¿ƒæƒ…ï¼ŒAI ä¸ºä½ ä½œç”»")
st.markdown("### å¤šæ¨¡æ€æƒ…æ„Ÿå¯è§†åŒ–ç³»ç»Ÿ (Multimodal Emotion Visualization)")

col1, col2 = st.columns([1, 4])

user_text = ""

with col1:
    st.markdown("#### ğŸ™ï¸ è¯­éŸ³ç¢ç¢å¿µ")
    if enable_voice:
        audio = mic_recorder(start_prompt="ç‚¹å‡»å½•éŸ³", stop_prompt="åœæ­¢å¹¶è¯†åˆ«", key='recorder')
        if audio:
            st.audio(audio['bytes'])
            '''
            è¿™é‡Œæˆ‘ä»¬ä¸ºäº†æ¼”ç¤ºç¨³å®šï¼Œæ¨¡æ‹Ÿäº†è¯­éŸ³è½¬æ–‡å­—çš„ç»“æœ
            çœŸå®é¡¹ç›®å¯æ¥å…¥ Whisper: st.write(whisper_model.transcribe(audio['bytes']))
            '''
            st.info("ğŸ”„ Whisper æ­£åœ¨è½¬å½•...")
            time.sleep(1)
            # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœï¼Œæ¼”ç¤ºæ—¶å¯ä»¥è¯´è¿™æ®µè¯
            simulated_text = "æœ€è¿‘å®éªŒä¸€ç›´å¤±è´¥ï¼Œå¯¼å¸ˆè¿˜è¦å‚¬è¿›åº¦ï¼Œæ„Ÿè§‰å‹åŠ›å¥½å¤§ï¼Œæƒ³å»æµ·è¾¹å¹å¹é£ã€‚" 
            user_text = st.text_area("è¯†åˆ«ç»“æœï¼š", value=simulated_text, height=100)
    else:
        st.info("è¯­éŸ³æ¨¡å—å·²å…³é—­")

with col2:
    if not user_text: 
        user_text = st.text_area("âœï¸ æ–‡å­—è®°å½•", placeholder="å†™ä¸‹æ­¤åˆ»çš„å¿ƒæƒ…ï¼Œè®© AI ä¸ºä½ ç”Ÿæˆä¸“å±é£æ™¯...", height=135)

if st.button("âœ¨ ç”Ÿæˆæˆ‘çš„å¿ƒæƒ…é£æ™¯"):
    if not user_text:
        st.warning("è¯·å…ˆè¾“å…¥æˆ–å½•å…¥å†…å®¹...")
    else:
        # 1. æƒ…æ„Ÿåˆ†æ
        with st.spinner("ğŸ§  ç¥ç»ç½‘ç»œæ­£åœ¨è§£ææƒ…ç»ªæˆåˆ†..."):
            result = classifier(user_text, candidate_labels, multi_label=False)
            top_label = result['labels'][0]
            top_score = result['scores'][0]
            time.sleep(0.5) # æ¼”ç¤ºèŠ‚å¥æ§åˆ¶

        

        mapping = {
            "ç„¦è™‘": {
                "prompt": "a lonely lighthouse in heavy fog, mysterious, calm ocean, minimal style, soothing colors",
                "sound_file": "sounds/ocean.mp3",  # æ”¹æˆæœ¬åœ°è·¯å¾„
                "sound_name": "ğŸŒŠ æ²»æ„ˆæµ·æµª (Ocean Waves)",
                "advice": "å¤§é›¾æ€»ä¼šæ•£å»ã€‚å¬å¬æµ·æµªçš„å£°éŸ³ï¼Œä¸“æ³¨äºå½“ä¸‹çš„å‘¼å¸ã€‚"
            },
            "æ‚²ä¼¤": {
                "prompt": "a girl holding umbrella in rain, reflection on wet street, lofi aesthetic, soft lighting, anime style",
                "sound_file": "sounds/rain.mp3",   # æ”¹æˆæœ¬åœ°è·¯å¾„
                "sound_name": "ğŸŒ§ï¸ çª—å¤–é›¨å£° (Soft Rain)",
                "advice": "å…è®¸è‡ªå·±éš¾è¿‡ä¸€ä¼šå„¿ã€‚è¿™åœºé›¨æ˜¯å¤©ç©ºåœ¨é™ªä½ å“­æ³£ã€‚"
            },
            "æ„¤æ€’": {
                "prompt": "burning fireplace in a cozy wooden cabin, snow outside window, warm atmosphere, hyperrealistic",
                "sound_file": "sounds/fire.mp3",   # æ”¹æˆæœ¬åœ°è·¯å¾„
                "sound_name": "ğŸ”¥ å£ç‚‰æŸ´ç« (Fireplace)",
                "advice": "å°†æ€’ç«è½¬åŒ–ä¸ºå£ç‚‰çš„æ¸©æš–ã€‚è¿™é‡Œå¾ˆå®‰å…¨ï¼Œä½ å¯ä»¥æ”¾æ¾ä¸‹æ¥ã€‚"
            },
            "æ²»æ„ˆ": {
                "prompt": "beautiful rainbow over a green meadow, sunny sky, ghibli style, vibrant colors",
                "sound_file": "sounds/piano.mp3",  # æ”¹æˆæœ¬åœ°è·¯å¾„
                "sound_name": "ğŸ¹ è½»æŸ”é’¢ç´ (Soft Piano)",
                "advice": "çœŸæ£’ï¼è®°ä½è¿™ä¸€åˆ»çš„é˜³å…‰ï¼ŒæŠŠå®ƒå­˜è¿›å¿ƒé‡Œã€‚"
            },
             "ç–²æƒ«": {
                "prompt": "starry night sky, milky way, quiet mountains, silhouette, dreamlike",
                "sound_file": "sounds/silence.mp3", # æ”¹æˆæœ¬åœ°è·¯å¾„
                "sound_name": "ğŸŒŒ é™è°§æ˜Ÿç©º (White Noise)",
                "advice": "ä¸–ç•Œç¡ç€äº†ï¼Œä½ ä¹Ÿå¯ä»¥ä¼‘æ¯äº†ã€‚æ™šå®‰ã€‚"
            }
        }
        
        current_mode = mapping.get(top_label, mapping["æ²»æ„ˆ"])

 
        apply_visual_theme(top_label)

        st.markdown("---")
        
        res_col1, res_col2 = st.columns([1, 1])
        
        with res_col1:
            st.markdown(f"### ğŸ–¼ï¸ AI ç”Ÿæˆçš„å¿ƒæƒ…ç”»å·ï¼š{top_label}")
            with st.spinner("ğŸ¨ Diffusion æ¨¡å‹æ­£åœ¨é€åƒç´ ç»˜åˆ¶..."):
                generated_img = generate_image(current_mode["prompt"])
                
                if generated_img:
                    st.image(generated_img, caption=f"Prompt: {current_mode['prompt']}", use_container_width=True)
                else:
                    st.error("GPU ç®—åŠ›ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")

        with res_col2:
            st.markdown(f"### ğŸ“Š æƒ…ç»ªåˆ†ææŠ¥å‘Š")
            st.progress(top_score, text=f"ä¸»è¦æƒ…ç»ªç½®ä¿¡åº¦: {top_score:.1%}")
            st.info(f"ğŸ’¡ **AI å»ºè®®**: {current_mode['advice']}")
            
            st.markdown("---")
            st.markdown("### ğŸ§ æ²‰æµ¸å¼å£°æ™¯")
            st.caption(f"å½“å‰å£°æº: {current_mode['sound_name']}")
            
            audio_bytes = load_local_audio(current_mode["sound_file"])
            
            if audio_bytes:

                st.audio(audio_bytes, format="audio/mp3", autoplay=auto_play_audio)
                
                if auto_play_audio:
                    st.toast(f"æ­£åœ¨è‡ªåŠ¨æ’­æ”¾: {current_mode['sound_name']}")